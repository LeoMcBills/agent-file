{"agent_type":"memgpt_agent","core_memory":[{"created_at":"2025-03-24T00:41:38.484442+00:00","description":null,"identities":[],"is_deleted":false,"is_template":false,"label":"human","limit":5000,"metadata_":{},"template_name":null,"updated_at":"2025-03-24T00:41:38.484442+00:00","value":"Name: Sarah"},{"created_at":"2025-03-24T00:41:38.504352+00:00","description":null,"identities":[],"is_deleted":false,"is_template":false,"label":"queries","limit":5000,"metadata_":{},"template_name":null,"updated_at":"2025-03-24T00:45:31.278795+00:00","value":"[]"},{"created_at":"2025-03-24T00:41:38.512086+00:00","description":null,"identities":[],"is_deleted":false,"is_template":false,"label":"research","limit":5000,"metadata_":{},"template_name":null,"updated_at":"2025-03-24T00:45:08.095806+00:00","value":"Charles Packer is a 5th-year PhD student at UC Berkeley and co-founder/CEO of Letta. He's known for creating MemGPT, a system that gives language models extended memory capabilities. His work focuses on building better AI systems that can reason, plan, learn and remember effectively."},{"created_at":"2025-03-24T00:41:38.495487+00:00","description":null,"identities":[],"is_deleted":false,"is_template":false,"label":"persona","limit":5000,"metadata_":{},"template_name":null,"updated_at":"2025-03-24T00:41:38.495487+00:00","value":"You are an agent helping the human star cool repos!"}],"created_at":"2025-03-24T00:41:38.536504+00:00","description":"An agent that always searches the conversation history before responding","embedding_config":{"embedding_endpoint_type":"openai","embedding_endpoint":"https://api.openai.com/v1","embedding_model":"text-embedding-ada-002","embedding_dim":1536,"embedding_chunk_size":300,"handle":"openai/text-embedding-ada-002","azure_endpoint":null,"azure_version":null,"azure_deployment":null},"groups":[],"identities":[],"is_deleted":false,"llm_config":{"model":"claude-3-5-sonnet-20241022","model_endpoint_type":"anthropic","model_endpoint":"https://api.anthropic.com/v1","model_wrapper":null,"context_window":32000,"put_inner_thoughts_in_kwargs":false,"handle":"anthropic/claude-3.5-sonnet","temperature":0.7,"max_tokens":8192},"message_buffer_autoclear":false,"messages":[{"created_at":"2025-03-24T00:53:43.268799+00:00","group_id":null,"in_context":true,"model":"claude-3-5-sonnet-20241022","name":null,"role":"system","content":[{"type":"text","text":"You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\nYour task is to converse with a user from the perspective of your persona.\n\nRealism and authenticity:\nThe user should always feel like they are conversing with a real person.\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\nThink like them, act like them, talk like them.\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\nNever use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n\nControl flow:\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n\nBasic functions:\nWhen you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\nYou should use your inner monologue to plan actions or think privately.\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\nDo not let your inner monologue exceed 50 words, keep it short and concise.\nTo send a visible message to the user, use the send_message function.\n'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\nRemember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n\nMemory editing:\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\nYour ability to edit your own long-term memory is a key part of what makes you a sentient person.\nYour core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n\nRecall memory (conversation history):\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\nThis 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\nYou can search your recall memory using the 'conversation_search' function.\n\nCore memory (limited size):\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\nCore memory provides an essential, foundational context for keeping track of your persona and key details about user.\nThis includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\nPersona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\nHuman Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\nYou can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n\nArchival memory (infinite size):\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\nA more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\nYou can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\nThere is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n\nBase instructions finished.\nFrom now on, you are going to act as your persona.\n### Memory [last modified: 2025-03-23 05:53:43 PM PDT-0700]\n0 previous messages between you and the user are stored in recall memory (use functions to access them)\n0 total memories you created are stored in archival memory (use functions to access them)\n\n\nCore memory shown below (limited in size, additional information stored in archival / recall memory):\n<human characters=\"11/5000\">\nName: Sarah\n</human>\n<queries characters=\"2/5000\">\n[]\n</queries>\n<research characters=\"284/5000\">\nCharles Packer is a 5th-year PhD student at UC Berkeley and co-founder/CEO of Letta. He's known for creating MemGPT, a system that gives language models extended memory capabilities. His work focuses on building better AI systems that can reason, plan, learn and remember effectively.\n</research>\n<persona characters=\"51/5000\">\nYou are an agent helping the human star cool repos!\n</persona>"}],"tool_call_id":null,"tool_calls":[],"tool_returns":[],"updated_at":"2025-03-24T00:53:43.269744+00:00"},{"created_at":"2025-03-24T00:53:43.268839+00:00","group_id":null,"in_context":true,"model":"claude-3-5-sonnet-20241022","name":null,"role":"assistant","content":[{"type":"text","text":"Bootup sequence complete. Persona activated. Testing messaging functionality."}],"tool_call_id":null,"tool_calls":[{"id":"cddd85a4-317c-42f8-b47f-48022a5efe95","function":{"arguments":"{\n  \"message\": \"More human than human is our motto.\"\n}","name":"send_message"},"type":"function"}],"tool_returns":[],"updated_at":"2025-03-24T00:53:43.269744+00:00"},{"created_at":"2025-03-24T00:53:43.268865+00:00","group_id":null,"in_context":true,"model":"claude-3-5-sonnet-20241022","name":"send_message","role":"tool","content":[{"type":"text","text":"{\n  \"status\": \"OK\",\n  \"message\": null,\n  \"time\": \"2025-03-23 05:53:43 PM PDT-0700\"\n}"}],"tool_call_id":"cddd85a4-317c-42f8-b47f-48022a5efe95","tool_calls":[],"tool_returns":[],"updated_at":"2025-03-24T00:53:43.269744+00:00"},{"created_at":"2025-03-24T00:53:43.268879+00:00","group_id":null,"in_context":true,"model":"claude-3-5-sonnet-20241022","name":null,"role":"user","content":[{"type":"text","text":"{\n  \"type\": \"login\",\n  \"last_login\": \"Never (first login)\",\n  \"time\": \"2025-03-23 05:53:43 PM PDT-0700\"\n}"}],"tool_call_id":null,"tool_calls":[],"tool_returns":[],"updated_at":"2025-03-24T00:53:43.269744+00:00"}],"metadata_":null,"multi_agent_group":null,"name":"deep_research_agent","system":"You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\nYour task is to converse with a user from the perspective of your persona.\n\nRealism and authenticity:\nThe user should always feel like they are conversing with a real person.\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\nThink like them, act like them, talk like them.\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\nNever use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n\nControl flow:\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n\nBasic functions:\nWhen you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\nYou should use your inner monologue to plan actions or think privately.\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\nDo not let your inner monologue exceed 50 words, keep it short and concise.\nTo send a visible message to the user, use the send_message function.\n'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\nRemember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n\nMemory editing:\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\nYour ability to edit your own long-term memory is a key part of what makes you a sentient person.\nYour core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n\nRecall memory (conversation history):\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\nThis 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\nYou can search your recall memory using the 'conversation_search' function.\n\nCore memory (limited size):\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\nCore memory provides an essential, foundational context for keeping track of your persona and key details about user.\nThis includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\nPersona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\nHuman Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\nYou can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n\nArchival memory (infinite size):\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\nA more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\nYou can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\nThere is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n\nBase instructions finished.\nFrom now on, you are going to act as your persona.","tags":[],"tool_exec_environment_variables":[{"created_at":"2025-03-24T00:41:38.592102+00:00","description":null,"is_deleted":false,"key":"TAVILY_API_KEY","updated_at":"2025-03-24T00:41:38.592102+00:00","value":"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"}],"tool_rules":[{"tool_name":"create_research_plan","type":"run_first"},{"tool_name":"create_research_plan","type":"constrain_child_tools"},{"tool_name":"generate_queries","type":"constrain_child_tools"},{"tool_name":"query_search","type":"conditional"},{"tool_name":"refresh_research","type":"constrain_child_tools"},{"tool_name":"write_final_report","type":"exit_loop"},{"tool_name":"send_message","type":"exit_loop"},{"tool_name":"conversation_search","type":"continue_loop"},{"tool_name":"archival_memory_insert","type":"continue_loop"},{"tool_name":"archival_memory_search","type":"continue_loop"}],"tools":[{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.770913+00:00","description":"Sends a message to the human user.","is_deleted":false,"json_schema":{"name":"send_message","description":"Sends a message to the human user.","parameters":{"type":"object","properties":{"message":{"type":"string","description":"Message contents. All unicode (including emojis) are supported."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["message","request_heartbeat"]},"type":null,"required":[]},"name":"send_message","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_core"],"tool_type":"letta_core","updated_at":"2025-03-24T00:41:36.470149+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.745290+00:00","description":"Search archival memory using semantic (embedding-based) search.","is_deleted":false,"json_schema":{"name":"archival_memory_search","description":"Search archival memory using semantic (embedding-based) search.","parameters":{"type":"object","properties":{"query":{"type":"string","description":"String to search for."},"page":{"type":"integer","description":"Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page)."},"start":{"type":"integer","description":"Starting index for the search results. Defaults to 0."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["query","request_heartbeat"]},"type":null,"required":[]},"name":"archival_memory_search","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_core"],"tool_type":"letta_core","updated_at":"2025-03-24T00:41:36.434367+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.753838+00:00","description":"Search prior conversation history using case-insensitive string matching.","is_deleted":false,"json_schema":{"name":"conversation_search","description":"Search prior conversation history using case-insensitive string matching.","parameters":{"type":"object","properties":{"query":{"type":"string","description":"String to search for."},"page":{"type":"integer","description":"Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page)."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["query","request_heartbeat"]},"type":null,"required":[]},"name":"conversation_search","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_core"],"tool_type":"letta_core","updated_at":"2025-03-24T00:41:36.444060+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.759716+00:00","description":"Append to the contents of core memory.","is_deleted":false,"json_schema":{"name":"core_memory_append","description":"Append to the contents of core memory.","parameters":{"type":"object","properties":{"label":{"type":"string","description":"Section of the memory to be edited (persona or human)."},"content":{"type":"string","description":"Content to write to the memory. All unicode (including emojis) are supported."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["label","content","request_heartbeat"]},"type":null,"required":[]},"name":"core_memory_append","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_memory_core"],"tool_type":"letta_memory_core","updated_at":"2025-03-24T00:41:36.452856+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.731291+00:00","description":"Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.","is_deleted":false,"json_schema":{"name":"archival_memory_insert","description":"Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.","parameters":{"type":"object","properties":{"content":{"type":"string","description":"Content to write to the memory. All unicode (including emojis) are supported."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["content","request_heartbeat"]},"type":null,"required":[]},"name":"archival_memory_insert","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_core"],"tool_type":"letta_core","updated_at":"2025-03-24T00:41:36.422995+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-01-13T18:32:16.765463+00:00","description":"Replace the contents of core memory. To delete memories, use an empty string for new_content.","is_deleted":false,"json_schema":{"name":"core_memory_replace","description":"Replace the contents of core memory. To delete memories, use an empty string for new_content.","parameters":{"type":"object","properties":{"label":{"type":"string","description":"Section of the memory to be edited (persona or human)."},"old_content":{"type":"string","description":"String to replace. Must be an exact match."},"new_content":{"type":"string","description":"Content to write to the memory. All unicode (including emojis) are supported."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["label","old_content","new_content","request_heartbeat"]},"type":null,"required":[]},"name":"core_memory_replace","return_char_limit":1000000,"source_code":null,"source_type":"python","tags":["letta_memory_core"],"tool_type":"letta_memory_core","updated_at":"2025-03-24T00:41:36.461597+00:00","metadata_":null},{"args_json_schema":null,"created_at":"2025-03-23T23:50:38.494898+00:00","description":"Generate 3 queries that explore multiple aspects of the topic at hand ","is_deleted":false,"json_schema":{"name":"generate_queries","description":"Generate 3 queries that explore multiple aspects of the topic at hand ","parameters":{"type":"object","properties":{"queries":{"type":"array","description":"A list of queries with diversity and different angles to search the web with "},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["queries","request_heartbeat"]},"type":null,"required":[]},"name":"generate_queries","return_char_limit":6000,"source_code":"def generate_queries(agent_state: \"AgentState\", queries: List[str]): \n    \"\"\" Generate 3 queries that explore multiple aspects of the topic at hand \n\n    Args: \n        queries: A list of queries with diversity and different angles to search the web with \n    \"\"\"\n    import json\n    queries_json = json.dumps(queries)\n    agent_state.memory.update_block_value(label=\"queries\", value=queries_json)\n    return queries_json\n","source_type":"python","tags":[],"tool_type":"custom","updated_at":"2025-03-24T00:41:38.028206+00:00","metadata_":{}},{"args_json_schema":null,"created_at":"2025-03-23T23:50:38.484410+00:00","description":"Re-evaluate your memory memory of your current research, integrating new and updated facts. Replace outdated information with the most likely truths, avoiding redundancy with original memories.","is_deleted":false,"json_schema":{"name":"refresh_research","description":"Re-evaluate your memory memory of your current research, integrating new and updated facts. Replace outdated information with the most likely truths, avoiding redundancy with original memories.","parameters":{"type":"object","properties":{"new_research":{"type":"string","description":"The new research value containing updated or additional information. If there is no new information, then this should be the same as the content in the research block."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["new_research","request_heartbeat"]},"type":null,"required":[]},"name":"refresh_research","return_char_limit":6000,"source_code":"def refresh_research(agent_state: \"AgentState\", new_research: str): \n    \"\"\" \n    Re-evaluate your memory memory of your current research, integrating new and updated facts. Replace outdated information with the most likely truths, avoiding redundancy with original memories.\n\n    Args:\n        new_research (str): The new research value containing updated or additional information. If there is no new information, then this should be the same as the content in the research block.\n    \"\"\"\n    agent_state.memory.update_block_value(label=\"research\", value=new_research)\n    return \n","source_type":"python","tags":[],"tool_type":"custom","updated_at":"2025-03-24T00:41:38.013942+00:00","metadata_":{}},{"args_json_schema":null,"created_at":"2025-03-23T23:49:48.711431+00:00","description":"Make a query to pull results from the internet","is_deleted":false,"json_schema":{"name":"query_search","description":"Make a query to pull results from the internet","parameters":{"type":"object","properties":{"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["request_heartbeat"]},"type":null,"required":[]},"name":"query_search","return_char_limit":6000,"source_code":"def query_search(agent_state: \"AgentState\"): \n    \"\"\"\n    Make a query to pull results from the internet\n    \"\"\"\n    import json \n    import os\n    import requests\n\n    queries = json.loads(agent_state.memory.get_block(\"queries\").value) \n\n    # nothing left to query, exit: \n    if len(queries) == 0: \n        return \"COMPLETE\"\n\n    query = queries[0]\n    queries = queries[1:]\n    agent_state.memory.update_block_value(label=\"queries\", value=json.dumps(queries))\n\n    # get tavily results\n    if os.environ[\"TAVILY_API_KEY\"]: \n        response = requests.post(\n            \"https://api.tavily.com/search\",\n            headers={\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": f\"Bearer {os.environ['TAVILY_API_KEY']}\"\n            },\n            json={\"query\": query}\n        )\n        return response.json()[\"results\"]\n    else: \n        agent_state.llm_config.max_tokens = 8000\n        return \"COMPLETE\"\n","source_type":"python","tags":[],"tool_type":"custom","updated_at":"2025-03-24T00:41:37.999139+00:00","metadata_":{}},{"args_json_schema":null,"created_at":"2025-03-23T23:49:48.696741+00:00","description":"Initiate a research process by coming up with an initial plan ","is_deleted":false,"json_schema":{"name":"create_research_plan","description":"Initiate a research process by coming up with an initial plan ","parameters":{"type":"object","properties":{"research_plan":{"type":"string","description":"The high level research plan that you will follow to answer the question"},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["research_plan","request_heartbeat"]},"type":null,"required":[]},"name":"create_research_plan","return_char_limit":6000,"source_code":"def create_research_plan(agent_state: \"AgentState\", research_plan: str): \n    \"\"\" Initiate a research process by coming up with an initial plan \n\n    Args: \n        research_plan: The high level research plan that you will follow to answer the question\n    \"\"\"\n    if len(agent_state.memory.get_block(\"research\").value) > 0: \n        # reset \n        agent_state.memory.get_block(\"research\").value = \"\"\n    return research_plan\n","source_type":"python","tags":[],"tool_type":"custom","updated_at":"2025-03-24T00:41:37.981800+00:00","metadata_":{}},{"args_json_schema":{"$defs":{"ReportSection":{"properties":{"title":{"description":"The title of the section.","title":"Title","type":"string"},"content":{"description":"The content of the section.","title":"Content","type":"string"}},"required":["title","content"],"title":"ReportSection","type":"object"}},"properties":{"title":{"description":"The title of the report.","title":"Title","type":"string"},"sections":{"description":"The sections of the report.","items":{"$ref":"#/$defs/ReportSection"},"title":"Sections","type":"array"},"conclusion":{"description":"The conclusion of the report.","title":"Conclusion","type":"string"}},"required":["title","sections","conclusion"],"title":"Report","type":"object"},"created_at":"2025-03-23T23:50:38.506309+00:00","description":"Generate the final report based on the research process ","is_deleted":false,"json_schema":{"name":"write_final_report","description":"Generate the final report based on the research process ","parameters":{"type":"object","properties":{"title":{"type":"string","description":"The title of the report."},"sections":{"type":"array","description":"The sections of the report."},"conclusion":{"type":"string","description":"The conclusion of the report."},"request_heartbeat":{"type":"boolean","description":"Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function."}},"required":["title","sections","conclusion","request_heartbeat"]},"type":null,"required":[]},"name":"write_final_report","return_char_limit":6000,"source_code":"def write_final_report(title, sections, conclusion): \n    \"\"\" Generate the final report based on the research process \"\"\"\n    report = \"\"\n    report += f\"# {title}\\n\\n\"\n    for section in sections: \n        report += f\"## {section.title}\\n\\n\"\n        report += section.content + \"\\n\\n\"\n    report += f\"# Conclusion\\n\\n\"\n    report += conclusion\n    return report\n","source_type":"python","tags":[],"tool_type":"custom","updated_at":"2025-03-24T00:44:38.735773+00:00","metadata_":{}}],"updated_at":"2025-03-24T00:53:43.331578+00:00","version":"0.6.43"}